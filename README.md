# ğŸ—ºï¸ Google Maps Scraper - Estrategia Apify

Script profesional de web scraping para Google Maps que replica la estrategia utilizada por Apify.

## ğŸ¯ CaracterÃ­sticas

- **GeolocalizaciÃ³n inteligente**: Convierte ubicaciones textuales en polÃ­gonos usando Nominatim
- **DivisiÃ³n geogrÃ¡fica**: Divide el Ã¡rea en segmentos para cobertura completa
- **BÃºsqueda multi-rubro**: Busca mÃºltiples categorÃ­as de negocios
- **Scroll infinito**: Maneja la paginaciÃ³n automÃ¡tica de Google Maps
- **Anti-detecciÃ³n**: Usa undetected-chromedriver y comportamiento humano
- **Checkpoints automÃ¡ticos**: Guarda progreso cada 20 empresas
- **Logs detallados**: Sistema de logging estilo Apify
- **RecuperaciÃ³n de errores**: Puede retomar desde donde se quedÃ³

## ğŸ“Š Datos ExtraÃ­dos

Para cada lugar/negocio extrae:

- Nombre del lugar
- DirecciÃ³n completa
- CategorÃ­a/rubro
- Rating/puntuaciÃ³n
- NÃºmero de reseÃ±as
- TelÃ©fono (cuando estÃ¡ disponible)
- Sitio web (cuando estÃ¡ disponible)
- Email (cuando estÃ¡ disponible)
- Coordenadas (latitud, longitud)
- URL de Google Maps

## ğŸ› ï¸ InstalaciÃ³n

### 1. Crear entorno virtual

```bash
python3 -m venv scraper
source scraper/bin/activate  # En Windows: scraper\Scripts\activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Verificar instalaciÃ³n

```bash
python -c "import selenium; import undetected_chromedriver; print('OK')"
```

## ğŸš€ Uso

### Uso bÃ¡sico

```bash
python main.py
```

Esto usarÃ¡ la configuraciÃ³n por defecto en `config.py`.

### Uso con parÃ¡metros personalizados

```bash
# Cambiar ubicaciÃ³n
python main.py --ubicacion "Buenos Aires, Argentina"

# Cambiar rubros
python main.py --rubros fabrica logistica transportes

# Cambiar tamaÃ±o de grid
python main.py --grid-size 3

# Modo headless
python main.py --headless

# CombinaciÃ³n
python main.py --ubicacion "Rosario, Argentina" --rubros "restaurante" "hotel" --grid-size 2
```

## âš™ï¸ ConfiguraciÃ³n

Edita `config.py` para personalizar:

```python
CONFIG = {
    'ubicacion': "CÃ³rdoba, Argentina",
    'rubros': ["fabrica", "logistica", "transportes"],
    'grid_size': 2,  # 2x2 = 4 segmentos
    'zoom_level': 13,
    'checkpoint_cada': 20,  # empresas
    'delays': {
        'entre_segmentos': (8, 15),
        'entre_rubros': (4, 8),
        'despues_scroll': (2, 4)
    }
}
```

## ğŸ“ Estructura del Proyecto

```
Scraper_Maps/
â”œâ”€â”€ main.py                      # Script principal
â”œâ”€â”€ config.py                    # ConfiguraciÃ³n
â”œâ”€â”€ geolocator.py               # GeolocalizaciÃ³n y segmentaciÃ³n
â”œâ”€â”€ segment_searcher.py         # BÃºsqueda por segmento
â”œâ”€â”€ detail_extractor.py         # ExtracciÃ³n de detalles
â”œâ”€â”€ data_manager.py             # GestiÃ³n de datos y checkpoints
â”œâ”€â”€ utils.py                    # Utilidades comunes
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ resultados/                 # Archivos Excel generados
â”œâ”€â”€ backups/                    # Backups automÃ¡ticos
â”œâ”€â”€ logs/                       # Logs de ejecuciÃ³n
â”œâ”€â”€ estado_ejecucion.json      # Estado para recuperaciÃ³n
â””â”€â”€ cookies.pkl                # Cookies de sesiÃ³n
```

## ğŸ“ˆ Proceso de EjecuciÃ³n

1. **GeolocalizaciÃ³n**: Convierte la ubicaciÃ³n en polÃ­gono
2. **SegmentaciÃ³n**: Divide el Ã¡rea en cuadrÃ­cula
3. **BÃºsqueda**: Para cada segmento y rubro:
   - Navega a Google Maps
   - Maneja scroll infinito
   - Extrae datos de lugares
4. **Almacenamiento**: Guarda en Excel con checkpoints

## ğŸ”§ Ejemplo de Logs

```
2024-01-24T10:30:00 INFO  ğŸ“¡ Geolocalizando: CÃ³rdoba, Argentina
2024-01-24T10:30:02 INFO  âœ… UbicaciÃ³n encontrada
2024-01-24T10:30:02 INFO  ğŸ“ Dividiendo Ã¡rea en cuadrÃ­cula de 2x2
2024-01-24T10:30:02 INFO  âœ… Creados 4 segmentos
2024-01-24T10:30:05 INFO  ğŸ” Buscando 'fabrica' en segmento 0
2024-01-24T10:30:45 INFO  ğŸ” [fabrica][-31.4201|-64.1888][SCROLL: 8]: Search page scraped: 42 unique, 5 duplicate, 47 seen, 8 paginations, 2 outOfLocation.
2024-01-24T10:30:45 INFO  ğŸ“Š 42 lugares agregados (Total: 42)
```

## âš ï¸ Consideraciones Importantes

### LÃ­mites de Google Maps

- Google puede detectar y bloquear scraping excesivo
- Usa delays apropiados entre solicitudes
- No ejecutes el script 24/7
- Considera usar la API oficial para uso comercial

### Uso Responsable

- Este script es para fines educativos
- Respeta los tÃ©rminos de servicio de Google
- No sobrecargues los servidores de Google
- Usa los datos de manera Ã©tica

### Anti-DetecciÃ³n

El script incluye:
- User-Agent rotation
- Delays aleatorios
- undetected-chromedriver
- Comportamiento similar al humano

AÃºn asÃ­, Google puede detectarlo. Para uso en producciÃ³n considera:
- Proxies rotativos
- DistribuciÃ³n de IPs
- API oficial de Google Places

## ğŸ› SoluciÃ³n de Problemas

### Error: "ChromeDriver not found"

```bash
# Instalar webdriver-manager
pip install webdriver-manager
```

### Error: "Shapely no funciona"

```bash
# En macOS
brew install geos

# En Ubuntu/Debian
sudo apt-get install libgeos-dev

# Reinstalar Shapely
pip uninstall shapely
pip install shapely --no-binary shapely
```

### El navegador se cierra inmediatamente

- Verifica que Chrome estÃ© instalado
- Usa modo no-headless para debugging
- Revisa los logs en `logs/`

### No se encuentran resultados

- Verifica la ubicaciÃ³n sea vÃ¡lida
- Revisa los selectores en `config.py` (Google puede cambiarlos)
- Aumenta los delays en la configuraciÃ³n
- Verifica tu conexiÃ³n a internet

## ğŸ“Š Salida de Datos

Los datos se guardan en:

- **Excel principal**: `resultados/google_maps_results.xlsx`
- **CSV**: `resultados/google_maps_results.csv`
- **Backups**: `backups/backup_YYYYMMDD_HHMMSS.xlsx`

Columnas del Excel:
- nombre
- direccion
- categoria
- rating
- num_resenas
- telefono
- sitio_web
- url_google_maps
- latitud
- longitud
- rubro_buscado
- segmento_id
- fecha_extraccion

## ğŸ”„ RecuperaciÃ³n de Errores

Si el script se interrumpe:

1. El estado se guarda en `estado_ejecucion.json`
2. Los datos parciales estÃ¡n en checkpoints
3. Al reiniciar, continuarÃ¡ desde donde se quedÃ³

Para empezar desde cero:

```bash
rm estado_ejecucion.json
rm resultados/*.xlsx
```

## ğŸ“ Licencia

Este proyecto es para fines educativos. Usa bajo tu propia responsabilidad.

## ğŸ¤ Contribuciones

Mejoras sugeridas:
- Implementar extracciÃ³n desde `APP_INITIALIZATION_STATE`
- Agregar soporte para proxies
- Implementar cola de tareas distribuida
- Mejorar detecciÃ³n de fin de resultados

## ğŸ“ Soporte

Para problemas o preguntas:
1. Revisa los logs en `logs/`
2. Verifica la configuraciÃ³n en `config.py`
3. Consulta la secciÃ³n de soluciÃ³n de problemas

---

**âš¡ Happy Scraping!**
