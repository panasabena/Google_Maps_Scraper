# üöÄ Gu√≠a de Inicio R√°pido

## Instalaci√≥n en 3 pasos

### 1. Crear entorno virtual y instalar dependencias

```bash
# Opci√≥n A: Usando el script autom√°tico (recomendado)
bash setup.sh

# Opci√≥n B: Manual
python3 -m venv scraper
source scraper/bin/activate  # En Windows: scraper\Scripts\activate
pip install -r requirements.txt
```

### 2. Verificar instalaci√≥n

```bash
python test.py
```

Si ves "‚úÖ Todas las pruebas pasaron", est√°s listo para continuar.

### 3. Ejecutar el scraper

```bash
python main.py
```

---

## Personalizar b√∫squeda

### Opci√≥n 1: Por l√≠nea de comandos

```bash
# Cambiar ubicaci√≥n
python main.py --ubicacion "Buenos Aires, Argentina"

# Cambiar rubros
python main.py --rubros "restaurante" "hotel" "gimnasio"

# Cambiar grid size
python main.py --grid-size 3

# Modo headless (sin ventana)
python main.py --headless

# Todo junto
python main.py --ubicacion "Rosario, Argentina" --rubros "fabrica" "logistica" --grid-size 2
```

### Opci√≥n 2: Editando config.py

```bash
# Edita el archivo config.py
nano config.py  # o usa tu editor favorito

# Cambia las siguientes l√≠neas:
'ubicacion': "TU_CIUDAD, PA√çS",
'rubros': ["rubro1", "rubro2", "rubro3"],
'grid_size': 2,

# Guarda y ejecuta
python main.py
```

---

## Ejemplos de uso

### Ejemplo 1: Buscar restaurantes en Buenos Aires

```bash
python main.py --ubicacion "Buenos Aires, Argentina" --rubros "restaurante" "bar" "cafeter√≠a"
```

### Ejemplo 2: Buscar f√°bricas en C√≥rdoba (2x2 grid)

```bash
python main.py --ubicacion "C√≥rdoba, Argentina" --rubros "fabrica" "industria" --grid-size 2
```

### Ejemplo 3: B√∫squeda exhaustiva con 9 segmentos

```bash
python main.py --ubicacion "Rosario, Santa Fe, Argentina" --rubros "logistica" "transportes" --grid-size 3
```

---

## Monitorear progreso

### Ver logs en tiempo real

```bash
# En otra terminal
tail -f logs/scraper_*.log
```

### Ver resultados parciales

Los resultados se guardan autom√°ticamente cada 20 empresas en:
- `resultados/google_maps_results.xlsx` (archivo principal)
- `backups/backup_TIMESTAMP.xlsx` (backups)

Puedes abrir estos archivos mientras el script est√° ejecutando.

---

## Pausar y reanudar

### Pausar

Presiona `Ctrl+C` en la terminal donde est√° ejecutando el scraper.

El script guardar√° el progreso actual autom√°ticamente.

### Reanudar

Simplemente ejecuta de nuevo:

```bash
python main.py
```

El script detectar√° el archivo `estado_ejecucion.json` y continuar√° desde donde se qued√≥.

### Empezar desde cero

```bash
rm estado_ejecucion.json
rm resultados/*.xlsx
python main.py
```

---

## Soluci√≥n r√°pida de problemas

### "ModuleNotFoundError: No module named 'X'"

```bash
source scraper/bin/activate  # Activar entorno virtual
pip install -r requirements.txt
```

### "ChromeDriver not found" o "Chrome not found"

Aseg√∫rate de tener Google Chrome instalado:
- macOS: Descarga desde https://www.google.com/chrome/
- Linux: `sudo apt install google-chrome-stable`

### "No se encontraron resultados"

1. Verifica tu conexi√≥n a internet
2. Aumenta los delays en `config.py`
3. Intenta con modo no-headless (`--headless` desactivado)

### El navegador se cierra inmediatamente

Ejecuta sin headless para ver qu√© est√° pasando:

```bash
python main.py  # Sin --headless
```

---

## Configuraci√≥n recomendada por caso de uso

### üèÉ R√°pido (pocos resultados, prueba)
```bash
python main.py --ubicacion "Tu Ciudad" --rubros "restaurante" --grid-size 1
```

### üö∂ Normal (balance velocidad/cobertura)
```bash
python main.py --ubicacion "Tu Ciudad" --rubros "rubro1" "rubro2" --grid-size 2
```

### üê¢ Exhaustivo (m√°xima cobertura)
```bash
python main.py --ubicacion "Tu Ciudad" --rubros "rubro1" "rubro2" "rubro3" --grid-size 4
```

---

## Tips importantes

1. **Empieza peque√±o**: Prueba con 1-2 rubros y grid-size 1 primero
2. **Monitorea los logs**: Te dir√°n exactamente qu√© est√° pasando
3. **S√© paciente**: Google Maps puede ser lento, especialmente con muchos resultados
4. **Usa delays apropiados**: No hagas scraping agresivo o Google te bloquear√°
5. **Backups autom√°ticos**: Se crean cada 20 empresas, no los borres
6. **Horarios**: Ejecuta preferiblemente en horarios de bajo tr√°fico

---

## Archivos importantes

- `main.py` - Script principal
- `config.py` - Configuraci√≥n
- `resultados/google_maps_results.xlsx` - Resultados finales
- `logs/scraper_*.log` - Logs de ejecuci√≥n
- `estado_ejecucion.json` - Estado para reanudar

---

## Siguiente paso

Una vez que obtengas resultados, puedes:

1. Abrir el Excel y filtrar/ordenar datos
2. Importar a tu CRM
3. Usar para an√°lisis de mercado
4. Exportar a otros formatos

Para m√°s detalles, consulta `README.md`.

---

**¬øTodo funcionando? ¬°Feliz scraping! üéâ**
